{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pandas\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)\n",
    "import numpy as np\n",
    "\n",
    "# Polars (Arrow)\n",
    "from pyarrow.dataset import dataset\n",
    "import polars as pl\n",
    "pl.Config.set_tbl_rows(n=-1)\n",
    "pl.Config.set_tbl_cols(n=-1)\n",
    "\n",
    "# Hit API\n",
    "import requests\n",
    "\n",
    "# Tools\n",
    "from itertools import chain\n",
    "from datetime import datetime, timedelta\n",
    "from math import pi\n",
    "\n",
    "# Save\n",
    "import pickle\n",
    "import json\n",
    "import os\n",
    "import pathlib\n",
    "\n",
    "# System Stats\n",
    "import psutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Memory: 15.73 GB\n",
      "Used Memory: 8.93 GB\n",
      "Free Memory: 6.80 GB\n",
      "PID: 4652, Name: MemCompression, Memory Usage: 653.34 MB\n",
      "PID: 24288, Name: Code.exe, Memory Usage: 302.16 MB\n",
      "PID: 4044, Name: explorer.exe, Memory Usage: 287.41 MB\n",
      "PID: 6368, Name: SearchHost.exe, Memory Usage: 279.33 MB\n",
      "PID: 21616, Name: Code.exe, Memory Usage: 265.54 MB\n"
     ]
    }
   ],
   "source": [
    "def get_mem_stats(n=5):\n",
    "    print(f\"Total Memory: {psutil.virtual_memory().total / (1024 ** 3):.2f} GB\")\n",
    "    print(f\"Used Memory: {psutil.virtual_memory().used / (1024 ** 3):.2f} GB\")\n",
    "    print(f\"Free Memory: {psutil.virtual_memory().free / (1024 ** 3):.2f} GB\")\n",
    "\n",
    "    # Get a list of running processes\n",
    "    processes = list(psutil.process_iter(['pid', 'name', 'memory_info']))\n",
    "\n",
    "    # Sort processes by memory usage\n",
    "    processes.sort(key=lambda x: x.info['memory_info'].rss, reverse=True)\n",
    "\n",
    "    # Print information about the top processes\n",
    "    for process in processes[:n]:  # Adjust the number to show more or fewer processes\n",
    "        print(f\"PID: {process.info['pid']}, Name: {process.info['name']}, Memory Usage: {process.info['memory_info'].rss / (1024 ** 2):.2f} MB\")\n",
    "\n",
    "get_mem_stats()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Most Current Rosters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr > th,\n",
       ".dataframe > tbody > tr > td {\n",
       "  text-align: right;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (5, 8)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>player_id</th><th>first_name</th><th>last_name</th><th>pos_F</th><th>pos_D</th><th>pos_G</th><th>hand_R</th><th>hand_L</th></tr><tr><td>i64</td><td>str</td><td>str</td><td>i64</td><td>i64</td><td>i64</td><td>i64</td><td>i64</td></tr></thead><tbody><tr><td>8473492</td><td>&quot;Matt&quot;</td><td>&quot;Beleskey&quot;</td><td>1</td><td>0</td><td>0</td><td>0</td><td>1</td></tr><tr><td>8474009</td><td>&quot;Nick&quot;</td><td>&quot;Bonino&quot;</td><td>1</td><td>0</td><td>0</td><td>0</td><td>1</td></tr><tr><td>8471699</td><td>&quot;Andrew&quot;</td><td>&quot;Cogliano&quot;</td><td>1</td><td>0</td><td>0</td><td>0</td><td>1</td></tr><tr><td>8462041</td><td>&quot;Radek&quot;</td><td>&quot;Dvorak&quot;</td><td>1</td><td>0</td><td>0</td><td>1</td><td>0</td></tr><tr><td>8475770</td><td>&quot;Emerson&quot;</td><td>&quot;Etem&quot;</td><td>1</td><td>0</td><td>0</td><td>0</td><td>1</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (5, 8)\n",
       "┌───────────┬────────────┬───────────┬───────┬───────┬───────┬────────┬────────┐\n",
       "│ player_id ┆ first_name ┆ last_name ┆ pos_F ┆ pos_D ┆ pos_G ┆ hand_R ┆ hand_L │\n",
       "│ ---       ┆ ---        ┆ ---       ┆ ---   ┆ ---   ┆ ---   ┆ ---    ┆ ---    │\n",
       "│ i64       ┆ str        ┆ str       ┆ i64   ┆ i64   ┆ i64   ┆ i64    ┆ i64    │\n",
       "╞═══════════╪════════════╪═══════════╪═══════╪═══════╪═══════╪════════╪════════╡\n",
       "│ 8473492   ┆ Matt       ┆ Beleskey  ┆ 1     ┆ 0     ┆ 0     ┆ 0      ┆ 1      │\n",
       "│ 8474009   ┆ Nick       ┆ Bonino    ┆ 1     ┆ 0     ┆ 0     ┆ 0      ┆ 1      │\n",
       "│ 8471699   ┆ Andrew     ┆ Cogliano  ┆ 1     ┆ 0     ┆ 0     ┆ 0      ┆ 1      │\n",
       "│ 8462041   ┆ Radek      ┆ Dvorak    ┆ 1     ┆ 0     ┆ 0     ┆ 1      ┆ 0      │\n",
       "│ 8475770   ┆ Emerson    ┆ Etem      ┆ 1     ┆ 0     ┆ 0     ┆ 0      ┆ 1      │\n",
       "└───────────┴────────────┴───────────┴───────┴───────┴───────┴────────┴────────┘"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Path\n",
    "roster_file = 'Data/NHL_Rosters_2014_2024.csv'\n",
    "\n",
    "# All Players - Connect To event_player_1_id, event_player_2_id, event_player_3_id, event_player_4_id, event_goalie_id, home_goalie, away_goalie\n",
    "ROSTER_DF_RAW = pl.read_csv(roster_file)\n",
    "\n",
    "ROSTER_DF = (\n",
    "    ROSTER_DF_RAW\n",
    "    .with_columns([\n",
    "        pl.col(\"player_id\").cast(pl.Int32),\n",
    "        (pl.col(\"first_name\").str.to_uppercase() + '.' + pl.col(\"last_name\").str.to_uppercase()).alias('player_name'),\n",
    "        pl.when((pl.col('pos_G') == 1) & (pl.col('hand_R') == 1)).then(pl.lit(1)).otherwise(pl.lit(0)).alias('G_hand_R'),\n",
    "        pl.when((pl.col('pos_G') == 1) & (pl.col('hand_L') == 1)).then(pl.lit(1)).otherwise(pl.lit(0)).alias('G_hand_L')\n",
    "        ])\n",
    "    .select(['player_id', 'player_name', 'hand_R', 'hand_L', 'pos_F', 'pos_D', 'pos_G', 'G_hand_R', 'G_hand_L'])\n",
    "    .unique()\n",
    ")\n",
    "\n",
    "ROSTER_DF_RAW.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get Game ID's From Previous Seasons\n",
    "\n",
    "- Saves two lists (Current Game IDs and All Game IDs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def align_and_cast_columns(data, sch):\n",
    "    # Identify missing and extra columns\n",
    "    missing_cols_int = set(sch.keys()) - set(data.columns)\n",
    "    extra_cols_int = set(data.columns) - set(sch.keys())\n",
    "    data = data.drop(extra_cols_int)\n",
    "\n",
    "    # Fill missing columns with null values and cast to the correct type\n",
    "    for col in sch.keys():\n",
    "\n",
    "        col_type = sch.get(col)\n",
    "\n",
    "        if (col in data.columns) & (col_type == 'str'):\n",
    "            data = data.with_columns(pl.col(col).cast(pl.Utf8).alias(col))\n",
    "        elif (col in data.columns) & (col_type == 'i32'):\n",
    "            data = data.with_columns(pl.col(col).cast(pl.Int32).alias(col))\n",
    "        elif (col in data.columns) & (col_type == 'f32'):\n",
    "            data = data.with_columns(pl.col(col).cast(pl.Float32).alias(col))\n",
    "        elif (col not in data.columns) & (col_type == 'str'):\n",
    "            data = data.with_columns(pl.lit(None).cast(pl.Utf8).alias(col))\n",
    "        elif (col not in data.columns) & (col_type == 'f32'):\n",
    "            data = data.with_columns(pl.lit(None).cast(pl.Float32).alias(col))\n",
    "\n",
    "    # Select columns and update schema\n",
    "    data = data.select(sch.keys())\n",
    "\n",
    "    return data\n",
    "\n",
    "# Master Schema For Union\n",
    "raw_schema = {\n",
    "    'id': 'i32',\n",
    "    'gameDate': 'str',\n",
    "    'season': 'i32',\n",
    "    'sortOrder': 'i32',\n",
    "    'gameType': 'i32',\n",
    "    'period': 'i32',\n",
    "    'periodDescriptor.periodType': 'str',\n",
    "    'timeRemaining': 'str',\n",
    "    'timeInPeriod': 'str',\n",
    "    'situationCode': 'str',\n",
    "    'homeTeamDefendingSide': 'str',\n",
    "    'details.eventOwnerTeamId': 'str',\n",
    "    'awayTeam.id': 'str',\n",
    "    'awayTeam.abbrev': 'str',\n",
    "    'details.awayScore': 'f32',\n",
    "    'homeTeam.id': 'str',\n",
    "    'homeTeam.abbrev': 'str',\n",
    "    'details.homeScore': 'f32',\n",
    "    'eventId': 'i32',\n",
    "    'typeCode': 'i32',\n",
    "    'details.typeCode': 'str',\n",
    "    'typeDescKey': 'str',\n",
    "    'details.descKey': 'str',\n",
    "    'details.reason': 'str',\n",
    "    'details.secondaryReason': 'str',\n",
    "    'details.shotType': 'str',\n",
    "    'details.zoneCode': 'str',\n",
    "    'details.xCoord': 'f32',\n",
    "    'details.yCoord': 'f32',\n",
    "    'details.scoringPlayerId': 'str',\n",
    "    'details.shootingPlayerId': 'str',\n",
    "    'details.goalieInNetId': 'str',\n",
    "    'details.blockingPlayerId': 'str',\n",
    "    'details.committedByPlayerId': 'str',\n",
    "    'details.drawnByPlayerId': 'str',\n",
    "    'details.servedByPlayerId': 'str',\n",
    "    'details.duration': 'str',\n",
    "    'details.hittingPlayerId': 'str',\n",
    "    'details.hitteePlayerId': 'str',\n",
    "    'details.winningPlayerId': 'str',\n",
    "    'details.losingPlayerId': 'str',\n",
    "    'details.assist1PlayerId': 'str',\n",
    "    'details.assist2PlayerId': 'str',\n",
    "    'details.playerId': 'str'    \n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining Load Functions: Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def min_to_sec(time_str):\n",
    "    \"\"\"This function will help to convert time's formatted like MM:SS to a round seconds number\"\"\"\n",
    "    if time_str is None:\n",
    "        return None\n",
    "    \n",
    "    minutes, seconds = map(int, time_str.split(':'))\n",
    "    return minutes * 60 + seconds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reconcile_api_data(data):\n",
    "    \"\"\" This Function will take a polars dataframe and reconcile column names, values, and data types to match SDV cleaning functions to save time and effort in building more tweak functions\"\"\"\n",
    "\n",
    "    # Create Dictionaries For Column Name/Value Rename\n",
    "    rename_dict = {\n",
    "        \"id\": \"game_id\",\n",
    "        \"gameDate\": \"game_date\",\n",
    "        \"awayTeam.id\": \"away_id\",\n",
    "        \"awayTeam.abbrev\": \"away_abbreviation\",\n",
    "        \"homeTeam.id\": \"home_id\",\n",
    "        \"homeTeam.abbrev\": \"home_abbreviation\",\n",
    "        \"gameType\": \"season_type\",\n",
    "        \"eventId\": \"event_id\",\n",
    "        \"typeDescKey\": \"event_type\",\n",
    "        \"sortOrder\": \"event_idx\",\n",
    "        \"periodDescriptor.periodType\": \"period_type\",\n",
    "        \"details.eventOwnerTeamId\": \"event_team_id\",\n",
    "        \"details.xCoord\": \"x\",\n",
    "        \"details.yCoord\": \"y\",\n",
    "        \"details.zoneCode\": \"event_zone\",\n",
    "        \"details.shotType\": \"secondary_type\",\n",
    "        \"details.awayScore\": \"away_score\",\n",
    "        \"details.homeScore\": \"home_score\",\n",
    "        \"details.goalieInNetId\": \"event_goalie_id\",\n",
    "        \"details.blockingPlayerId\": \"blocking_player_id\",\n",
    "        \"details.drawnByPlayerId\": \"drawnby_player_id\",\n",
    "        \"details.servedByPlayerId\": \"servedby_player_id\",\n",
    "        \"details.committedByPlayerId\": \"committedby_player_id\",\n",
    "        \"details.hittingPlayerId\": \"hitting_player_id\",\n",
    "        \"details.hitteePlayerId\": \"hittee_player_id\",\n",
    "        \"details.assist1PlayerId\": \"assist_1_player_id\",\n",
    "        \"details.assist2PlayerId\": \"assist_2_player_id\",\n",
    "        \"details.shootingPlayerId\": \"shooting_player_id\",\n",
    "        \"details.reason\": \"reason\",\n",
    "        \"details.scoringPlayerId\": \"scoring_player_id\",\n",
    "        \"details.duration\": \"penalty_minutes\",\n",
    "        \"details.winningPlayerId\": \"winning_player_id\",\n",
    "        \"details.losingPlayerId\": \"losing_player_id\"\n",
    "    }\n",
    "\n",
    "    # Event Type\n",
    "    event_type_dict = {\n",
    "        \"faceoff\": \"FACEOFF\",\n",
    "        \"shot-on-goal\": \"SHOT\",\n",
    "        \"stoppage\": \"STOPPAGE\",\n",
    "        \"hit\": \"HIT\",\n",
    "        \"blocked-shot\": \"BLOCKED_SHOT\",\n",
    "        \"missed-shot\": \"MISSED_SHOT\",\n",
    "        \"giveaway\": \"GIVEAWAY\",\n",
    "        \"takeaway\": \"TAKEAWAY\",\n",
    "        \"penalty\": \"PENALTY\",\n",
    "        \"goal\": \"GOAL\",\n",
    "        \"period-start\": \"PERIOD_START\",\n",
    "        \"period-end\": \"PERIOD_END\",\n",
    "        \"delayed-penalty\": \"DELAYED_PENALTY\",\n",
    "        \"game-end\": \"GAME_END\",\n",
    "        \"shootout-complete\": \"SHOOTOUT_COMPLETE\",\n",
    "        \"failed-shot-attempt\": \"FAILED_SHOT\",\n",
    "        None:None\n",
    "    }\n",
    "\n",
    "    # Season Type\n",
    "    season_type_dict = {\n",
    "        2: \"R\",\n",
    "        3: \"P\",\n",
    "        None:None\n",
    "    }\n",
    "\n",
    "    # Shot Type\n",
    "    shot_type_dict = {\n",
    "        \"snap\": \"Snap\",\n",
    "        \"between-legs\": \"Between Legs\",\n",
    "        \"wrap-around\": \"Wrap-Around\",\n",
    "        \"tip-in\": \"Tip-In\",\n",
    "        \"cradle\": \"Wrap-Around\",\n",
    "        \"poke\": 'Poked',\n",
    "        \"bat\": 'Batted',\n",
    "        \"deflected\": \"Deflected\",\n",
    "        \"wrist\": \"Wrist\",\n",
    "        \"slap\":\t\"Slap\",\n",
    "        \"backhand\": \"Backhand\",\n",
    "        None: None\n",
    "    }\n",
    "\n",
    "    # Rename Columns + Values AND Add Event/Season Type Helpers\n",
    "    data = data.rename(rename_dict).filter((pl.col('period_type') != 'SO') & (pl.col('season_type').is_in([2, 3])))\n",
    "\n",
    "    data = (\n",
    "        data\n",
    "        .with_columns([\n",
    "            (pl.col('season_type').map_dict(season_type_dict, default = pl.col('season_type'))).alias('season_type'),\n",
    "            (pl.col('event_type').map_dict(event_type_dict,default = pl.col('event_type'))).alias('event_type'),\n",
    "            (pl.col('secondary_type').map_dict(shot_type_dict,default = pl.col('secondary_type'))).alias('secondary_type'),\n",
    "            pl.when(pl.col('event_team_id') == pl.col('home_id')).then(pl.lit('home')).otherwise(pl.lit('away')).alias('event_team_type'),\n",
    "            pl.when(pl.col('event_team_id') == pl.col('home_id')).then(pl.lit('home_abbreviation')).otherwise(pl.lit('away_abbreviation')).alias('event_team_abbr')\n",
    "            ])\n",
    "        #.drop('gameType', 'typeDescKey', 'details.shotType')\n",
    "        .filter(~pl.col('situationCode').is_in([\"PERIOD_START\", \"PERIOD_END\", \"GAME_START\", \"GAME_END\"]))\n",
    "    )\n",
    "\n",
    "    # Create Game and Period Seconds Remaining from timeInPeriod, timeRemaining: 'period', 'period_seconds', 'period_seconds_remaining', 'game_seconds', 'game_seconds_remaining'\n",
    "    data = (\n",
    "        data\n",
    "        .with_columns(pl.when(pl.col('timeInPeriod').is_null()).then(pl.lit(None)).otherwise(pl.col('timeInPeriod').apply(min_to_sec)).alias('period_seconds'))\n",
    "        .with_columns([\n",
    "            (1200 - pl.col('period_seconds')).alias('period_seconds_remaining'),\n",
    "            (pl.col('period_seconds') + ((pl.col('period')-1)*1200)).alias('game_seconds'),\n",
    "            ((3600 - pl.col('period_seconds')) + ((pl.col('period') - 3) * 1200)).alias('game_seconds_remaining')\n",
    "        ])\n",
    "    )\n",
    "\n",
    "    # Create event_player_1_id and event_player_2_id columns based on event_type and corresponding columns\n",
    "    remove_ply_ids = ['winning_player_id', 'hitting_player_id', 'scoring_player_id', 'shooting_player_id', 'committedby_player_id',\n",
    "                      'details.playerId', 'losing_player_id', 'hittee_player_id', 'drawnby_player_id', 'assist_1_player_id', 'assist_2_player_id',\n",
    "                      'blocking_player_id']\n",
    "    data = (\n",
    "        data\n",
    "        .with_columns([\n",
    "            (pl.when(pl.col('event_type') == 'FACEOFF').then(pl.col('winning_player_id'))\n",
    "               .when(pl.col('event_type') == 'HIT').then(pl.col('hitting_player_id'))\n",
    "               .when(pl.col('event_type') == 'GOAL').then(pl.col('scoring_player_id'))\n",
    "               .when(pl.col('event_type').is_in(['SHOT', 'MISSED_SHOT', \"BLOCKED_SHOT\"])).then(pl.col('shooting_player_id'))\n",
    "               .when(pl.col('event_type') == 'PENALTY').then(pl.col('committedby_player_id'))\n",
    "               .when(pl.col('event_type') == 'GIVEAWAY').then(pl.col('details.playerId'))\n",
    "               .when(pl.col('event_type') == 'TAKEAWAY').then(pl.col('details.playerId'))\n",
    "               .otherwise(pl.lit(None))\n",
    "             ).alias(\"event_player_1_id\"),\n",
    "             (pl.when(pl.col('event_type') == 'FACEOFF').then(pl.col('losing_player_id'))\n",
    "               .when(pl.col('event_type') == 'HIT').then(pl.col('hittee_player_id'))\n",
    "               .when(pl.col('event_type').is_in(['GOAL','SHOT', 'MISSED_SHOT', 'BLOCKED_SHOT'])).then(pl.col('event_goalie_id'))\n",
    "               .when(pl.col('event_type') == 'PENALTY').then(pl.col('drawnby_player_id'))\n",
    "               .otherwise(pl.lit(None))\n",
    "             ).alias(\"event_player_2_id\"),\n",
    "             (pl.when((pl.col('event_type') == 'GOAL') & (~pl.col('assist_1_player_id').is_null())).then(pl.col('assist_1_player_id'))\n",
    "               .when((pl.col('event_type') == 'PENALTY') & (~pl.col('servedby_player_id').is_null())).then(pl.col('servedby_player_id'))\n",
    "               .when((pl.col('event_type') == 'BLOCKED_SHOT') & (~pl.col('blocking_player_id').is_null())).then(pl.col('blocking_player_id'))\n",
    "               .otherwise(pl.lit(None))\n",
    "             ).alias(\"event_player_3_id\"),\n",
    "             (pl.when((pl.col('event_type') == 'GOAL') & (~pl.col('assist_2_player_id').is_null())).then(pl.col('assist_2_player_id'))\n",
    "               .otherwise(pl.lit(None))\n",
    "             ).alias(\"event_player_4_id\"),\n",
    "             (pl.when(pl.col('event_type') == 'FACEOFF').then(pl.lit('Winner'))\n",
    "               .when(pl.col('event_type') == 'HIT').then(pl.lit('Hitter'))\n",
    "               .when(pl.col('event_type') == 'GOAL').then(pl.lit('Scorer'))\n",
    "               .when(pl.col('event_type').is_in(['SHOT', 'MISSED_SHOT', \"BLOCKED_SHOT\"])).then(pl.lit('Shooter'))\n",
    "               .when(pl.col('event_type') == 'PENALTY').then(pl.lit('PenaltyOn'))\n",
    "               .when(pl.col('event_type') == 'GIVEAWAY').then(pl.lit('PlayerID'))\n",
    "               .when(pl.col('event_type') == 'TAKEAWAY').then(pl.lit('PlayerID'))\n",
    "               .otherwise(pl.lit(None))\n",
    "             ).alias(\"event_player_1_type\"),\n",
    "             (pl.when(pl.col('event_type') == 'FACEOFF').then(pl.lit('Loser'))\n",
    "               .when(pl.col('event_type') == 'HIT').then(pl.lit('Hittee'))\n",
    "               .when((pl.col('event_type') == 'GOAL') & (~pl.col('event_goalie_id').is_null())).then(pl.lit('Goalie'))\n",
    "               .when((pl.col('event_type') == 'GOAL') & (pl.col('event_goalie_id').is_null())).then(pl.lit('EmptyNet'))\n",
    "               .when(pl.col('event_type').is_in(['SHOT', 'MISSED_SHOT', 'BLOCKED_SHOT'])).then(pl.lit('Goalie'))\n",
    "               .when(pl.col('event_type') == 'PENALTY').then(pl.lit('DrewBy'))\n",
    "               .when(pl.col('event_type') == 'GIVEAWAY').then(pl.lit('PlayerID'))\n",
    "               .when(pl.col('event_type') == 'TAKEAWAY').then(pl.lit('PlayerID'))\n",
    "               .otherwise(pl.lit(None))\n",
    "             ).alias(\"event_player_2_type\"),\n",
    "             (pl.when((pl.col('event_type') == 'GOAL') & (~pl.col('assist_1_player_id').is_null())).then(pl.lit('Assist'))\n",
    "               .when((pl.col('event_type') == 'PENALTY') & (~pl.col('servedby_player_id').is_null())).then(pl.lit('ServedBy'))\n",
    "               .when((pl.col('event_type') == 'BLOCKED_SHOT') & (~pl.col('blocking_player_id').is_null())).then(pl.lit('Blocker'))\n",
    "               .otherwise(pl.lit(None))\n",
    "             ).alias(\"event_player_3_type\"),\n",
    "             (pl.when((pl.col('event_type') == 'GOAL') & (~pl.col('assist_2_player_id').is_null())).then(pl.lit('Assist'))\n",
    "               .otherwise(pl.lit(None))\n",
    "             ).alias(\"event_player_4_type\")\n",
    "        ])\n",
    "        .drop(remove_ply_ids)\n",
    "    )\n",
    "    # Parse Situation Code For Home/Away Skaters/EmptyNet\n",
    "    data = (\n",
    "        data\n",
    "        .sort('season', 'game_id', 'period', 'event_idx')\n",
    "        .with_columns(\n",
    "            pl.when(pl.col('situationCode').is_null()).then(pl.col(\"situationCode\").fill_null(strategy=\"forward\")).otherwise(pl.col('situationCode')).alias('situationCode')\n",
    "        )\n",
    "        .filter(~pl.col('situationCode').is_in(['0101', '1010']))\n",
    "        .with_columns([\n",
    "            pl.col(\"situationCode\").str.slice(0, 1).cast(pl.Int32).alias(\"away_en\"),\n",
    "            pl.col(\"situationCode\").str.slice(3, 1).cast(pl.Int32).alias(\"home_en\"),\n",
    "            pl.col(\"situationCode\").str.slice(1, 1).cast(pl.Int32).alias(\"away_skaters\"),\n",
    "            pl.col(\"situationCode\").str.slice(2, 1).cast(pl.Int32).alias(\"home_skaters\")\n",
    "        ])\n",
    "        .with_columns([\n",
    "            (pl.concat_str([pl.col('home_skaters'), pl.lit('v'), pl.col('away_skaters')])).alias('strength_state'),\n",
    "            (pl.concat_str([pl.col('home_skaters'), pl.lit('v'), pl.col('away_skaters')])).alias('true_strength_state')\n",
    "        ])\n",
    "    )\n",
    "\n",
    "    # Create x_fixed and y_fixed. These coordinates will be relative to the event team's attacking zone (i.e., x_abs is positive)\n",
    "    data = (\n",
    "        data\n",
    "        .with_columns([\n",
    "            pl.when((pl.col('event_zone') == 'O') & (pl.col('x').mean() > 0)).then(pl.lit(1)).otherwise(pl.lit(-1)).alias('flipped_coords')\n",
    "        ])\n",
    "        .with_columns([\n",
    "            # Where homeTeamDefendingSide Exists\n",
    "            (pl.when((~pl.col('homeTeamDefendingSide').is_null()) &\n",
    "                     ( pl.col('homeTeamDefendingSide') == 'left') &\n",
    "                     ( pl.col('event_team_type') == 'home'))\n",
    "                     .then(pl.col('x'))\n",
    "               .when((~pl.col('homeTeamDefendingSide').is_null()) &\n",
    "                     ( pl.col('homeTeamDefendingSide') == 'right') &\n",
    "                     ( pl.col('event_team_type') == 'home'))\n",
    "                     .then(pl.col('x')*-1)\n",
    "               .when((~pl.col('homeTeamDefendingSide').is_null()) &\n",
    "                     ( pl.col('homeTeamDefendingSide') == 'left') &\n",
    "                     ( pl.col('event_team_type') == 'away'))\n",
    "                     .then(pl.col('x')*-1)\n",
    "               .when((~pl.col('homeTeamDefendingSide').is_null()) &\n",
    "                     ( pl.col('homeTeamDefendingSide') == 'right') &\n",
    "                     ( pl.col('event_team_type') == 'away'))\n",
    "                     .then(pl.col('x'))\n",
    "              # Where homeTeamDefendingSide does not exist\n",
    "              .when((pl.col('homeTeamDefendingSide').is_null()) &\n",
    "                    (pl.col('event_zone') == 'O'))\n",
    "                    .then(pl.col('x').abs())\n",
    "              .when((pl.col('homeTeamDefendingSide').is_null()) &\n",
    "                    (pl.col('event_zone') == 'D'))\n",
    "                    .then((pl.col('x').abs())*-1)\n",
    "              .when((pl.col('homeTeamDefendingSide').is_null()) &\n",
    "                    (pl.col('event_zone') == 'N'))\n",
    "                    .then((pl.col('x')) * (pl.col('flipped_coords').max().over(['season', 'game_id', 'period'])))\n",
    "              .otherwise(pl.lit(None)).alias('x_abs')\n",
    "            ),\n",
    "            # Where homeTeamDefendingSide does exist\n",
    "            (pl.when((~pl.col('homeTeamDefendingSide').is_null()) &\n",
    "                     ( pl.col('homeTeamDefendingSide') == 'left') &\n",
    "                     ( pl.col('event_team_type') == 'home'))\n",
    "                     .then(pl.col('y'))\n",
    "               .when((~pl.col('homeTeamDefendingSide').is_null()) &\n",
    "                     ( pl.col('homeTeamDefendingSide') == 'right') &\n",
    "                     ( pl.col('event_team_type') == 'home'))\n",
    "                     .then(pl.col('y')*-1)\n",
    "               .when((~pl.col('homeTeamDefendingSide').is_null()) &\n",
    "                     ( pl.col('homeTeamDefendingSide') == 'left') &\n",
    "                     ( pl.col('event_team_type') == 'away'))\n",
    "                     .then(pl.col('y')*-1)\n",
    "               .when((~pl.col('homeTeamDefendingSide').is_null()) &\n",
    "                     ( pl.col('homeTeamDefendingSide') == 'right') &\n",
    "                     ( pl.col('event_team_type') == 'away'))\n",
    "                     .then(pl.col('y'))\n",
    "              # Where homeTeamDefendingSide does not exist\n",
    "              .when((pl.col('homeTeamDefendingSide').is_null()) &\n",
    "                    (pl.col('event_zone') == 'O'))\n",
    "                    .then(pl.col('y').abs())\n",
    "              .when((pl.col('homeTeamDefendingSide').is_null()) &\n",
    "                    (pl.col('event_zone') == 'D'))\n",
    "                    .then((pl.col('y').abs())*-1)\n",
    "              .when((pl.col('homeTeamDefendingSide').is_null()) &\n",
    "                    (pl.col('event_zone') == 'N'))\n",
    "                    .then((pl.col('y')) * (pl.col('flipped_coords').max().over(['season', 'game_id', 'period'])))\n",
    "              .otherwise(pl.lit(None)).alias('y_abs')\n",
    "            )\n",
    "        ])\n",
    "        .drop(\"flipped_coords\")\n",
    "    )\n",
    "\n",
    "    # Create Event Distance Calculation\n",
    "    data = data.with_columns(\n",
    "        pl.when(pl.col('x_abs') >= 0).then(pl.Series.sqrt((89 - pl.Series.abs(data['x_abs']))**2 + data['y_abs']**2))\n",
    "          .when(pl.col('x_abs') <  0).then(pl.Series.sqrt((pl.Series.abs(data['x_abs']) + 89)**2 + data['y_abs']**2))\n",
    "          .alias('event_distance')\n",
    "    )\n",
    "\n",
    "    # Create Event Angle Calculation\n",
    "    data = (\n",
    "        data\n",
    "        .with_columns(\n",
    "        pl.when(data['x_abs'] >= 0)\n",
    "          .then(pl.Series.arctan(data['y_abs'] / (89 - pl.Series.abs(data['x_abs'])))\n",
    "                .apply(lambda x: abs(x * (180 / pi))))\n",
    "          .when(data['x_abs'] < 0)\n",
    "          .then(pl.Series.arctan(data['y_abs'] / (pl.Series.abs(data['x_abs']) + 89))\n",
    "                .apply(lambda x: abs(x * (180 / pi))))\n",
    "          .alias('event_angle')\n",
    "        )\n",
    "        .with_columns(\n",
    "            pl.when(pl.col('x_abs') > 89).then((180 - pl.col('event_angle'))).otherwise(pl.col('event_angle')).alias('event_angle')\n",
    "        )\n",
    "    )\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr > th,\n",
       ".dataframe > tbody > tr > td {\n",
       "  text-align: right;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (5, 10)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>id</th><th>endTime</th><th>firstName</th><th>gameId</th><th>lastName</th><th>period</th><th>playerId</th><th>startTime</th><th>teamAbbrev</th><th>teamId</th></tr><tr><td>i64</td><td>str</td><td>str</td><td>i64</td><td>str</td><td>i64</td><td>i64</td><td>str</td><td>str</td><td>i64</td></tr></thead><tbody><tr><td>2066098</td><td>&quot;00:29&quot;</td><td>&quot;Kimmo&quot;</td><td>2012020001</td><td>&quot;Timonen&quot;</td><td>1</td><td>8459670</td><td>&quot;00:00&quot;</td><td>&quot;PHI&quot;</td><td>4</td></tr><tr><td>2066099</td><td>&quot;02:12&quot;</td><td>&quot;Kimmo&quot;</td><td>2012020001</td><td>&quot;Timonen&quot;</td><td>1</td><td>8459670</td><td>&quot;01:33&quot;</td><td>&quot;PHI&quot;</td><td>4</td></tr><tr><td>2066100</td><td>&quot;03:46&quot;</td><td>&quot;Kimmo&quot;</td><td>2012020001</td><td>&quot;Timonen&quot;</td><td>1</td><td>8459670</td><td>&quot;02:47&quot;</td><td>&quot;PHI&quot;</td><td>4</td></tr><tr><td>2066101</td><td>&quot;04:40&quot;</td><td>&quot;Kimmo&quot;</td><td>2012020001</td><td>&quot;Timonen&quot;</td><td>1</td><td>8459670</td><td>&quot;04:36&quot;</td><td>&quot;PHI&quot;</td><td>4</td></tr><tr><td>2066102</td><td>&quot;06:09&quot;</td><td>&quot;Kimmo&quot;</td><td>2012020001</td><td>&quot;Timonen&quot;</td><td>1</td><td>8459670</td><td>&quot;04:50&quot;</td><td>&quot;PHI&quot;</td><td>4</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (5, 10)\n",
       "┌─────────┬─────────┬──────────┬─────────┬─────────┬────────┬─────────┬─────────┬─────────┬────────┐\n",
       "│ id      ┆ endTime ┆ firstNam ┆ gameId  ┆ lastNam ┆ period ┆ playerI ┆ startTi ┆ teamAbb ┆ teamId │\n",
       "│ ---     ┆ ---     ┆ e        ┆ ---     ┆ e       ┆ ---    ┆ d       ┆ me      ┆ rev     ┆ ---    │\n",
       "│ i64     ┆ str     ┆ ---      ┆ i64     ┆ ---     ┆ i64    ┆ ---     ┆ ---     ┆ ---     ┆ i64    │\n",
       "│         ┆         ┆ str      ┆         ┆ str     ┆        ┆ i64     ┆ str     ┆ str     ┆        │\n",
       "╞═════════╪═════════╪══════════╪═════════╪═════════╪════════╪═════════╪═════════╪═════════╪════════╡\n",
       "│ 2066098 ┆ 00:29   ┆ Kimmo    ┆ 2012020 ┆ Timonen ┆ 1      ┆ 8459670 ┆ 00:00   ┆ PHI     ┆ 4      │\n",
       "│         ┆         ┆          ┆ 001     ┆         ┆        ┆         ┆         ┆         ┆        │\n",
       "│ 2066099 ┆ 02:12   ┆ Kimmo    ┆ 2012020 ┆ Timonen ┆ 1      ┆ 8459670 ┆ 01:33   ┆ PHI     ┆ 4      │\n",
       "│         ┆         ┆          ┆ 001     ┆         ┆        ┆         ┆         ┆         ┆        │\n",
       "│ 2066100 ┆ 03:46   ┆ Kimmo    ┆ 2012020 ┆ Timonen ┆ 1      ┆ 8459670 ┆ 02:47   ┆ PHI     ┆ 4      │\n",
       "│         ┆         ┆          ┆ 001     ┆         ┆        ┆         ┆         ┆         ┆        │\n",
       "│ 2066101 ┆ 04:40   ┆ Kimmo    ┆ 2012020 ┆ Timonen ┆ 1      ┆ 8459670 ┆ 04:36   ┆ PHI     ┆ 4      │\n",
       "│         ┆         ┆          ┆ 001     ┆         ┆        ┆         ┆         ┆         ┆        │\n",
       "│ 2066102 ┆ 06:09   ┆ Kimmo    ┆ 2012020 ┆ Timonen ┆ 1      ┆ 8459670 ┆ 04:50   ┆ PHI     ┆ 4      │\n",
       "│         ┆         ┆          ┆ 001     ┆         ┆        ┆         ┆         ┆         ┆        │\n",
       "└─────────┴─────────┴──────────┴─────────┴─────────┴────────┴─────────┴─────────┴─────────┴────────┘"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shift_link = \"https://api.nhle.com/stats/rest/en/shiftcharts?cayenneExp=gameId=\"+str(2012020001)\n",
    "shift_response = requests.get(shift_link).json()\n",
    "# Assuming \"data\" is the key containing nested data\n",
    "data_list = shift_response.get('data', [])\n",
    "keep_keys = ['id', 'endTime', 'firstName', 'gameId', 'lastName', 'period', 'playerId', 'startTime', 'teamAbbrev', 'teamId']\n",
    "filtered_data = [{key: item[key] for key in keep_keys} for item in data_list]\n",
    "pl.DataFrame(filtered_data).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def append_shift_data(data):\n",
    "    \"\"\" This function will load shift data allowing the user to see which players are on the ice at a given time in each game\"\"\"\n",
    "    # Load Game ID and Home/Away Ids\n",
    "    i = data['game_id'][0]\n",
    "\n",
    "    game_info_slim = (\n",
    "        data\n",
    "        .filter(pl.col('game_id') == i)\n",
    "        .select('game_id', 'home_id', 'away_id', 'period', 'game_seconds', 'period_seconds', 'event_id', 'event_idx', 'event_type')\n",
    "        .unique()\n",
    "    )\n",
    "\n",
    "    shift_link = \"https://api.nhle.com/stats/rest/en/shiftcharts?cayenneExp=gameId=\"+str(i)\n",
    "    shift_response = requests.get(shift_link).json()\n",
    "\n",
    "    # Assuming \"data\" is the key containing nested data\n",
    "    data_list = shift_response.get('data', [])\n",
    "    keep_keys = ['id', 'endTime', 'firstName', 'gameId', 'lastName', 'period', 'playerId', 'startTime', 'teamAbbrev', 'teamId']\n",
    "    filtered_data = [{key: item[key] for key in keep_keys} for item in data_list]\n",
    "    shift_raw = pl.DataFrame(filtered_data)\n",
    "    shift_raw = (\n",
    "        shift_raw\n",
    "        .with_columns([\n",
    "            (pl.col('firstName') + ' ' + pl.col('lastName')).alias('player_name'),\n",
    "            ((pl.col('startTime').str.slice(0, 2).cast(pl.Int32) * 60) + (pl.col('startTime').str.slice(3, 5).cast(pl.Int32))).alias('period_start_seconds'),\n",
    "            ((pl.col('endTime').str.slice(0, 2).cast(pl.Int32) * 60) + (pl.col('endTime').str.slice(3, 5).cast(pl.Int32))).alias('period_end_seconds')\n",
    "        ])\n",
    "        .with_columns([\n",
    "            (pl.col('period_start_seconds') + ((pl.col('period') - 1) * 1200)).alias('game_start_seconds'),\n",
    "            (pl.col('period_end_seconds') + ((pl.col('period') - 1) * 1200)).alias('game_end_seconds'),\n",
    "        ])\n",
    "        .rename({\n",
    "                'gameId': 'game_id',\n",
    "                'id': 'shift_id',\n",
    "                'playerId': 'player_id',\n",
    "                'teamId': 'team_id',\n",
    "                'teamAbbrev': 'team_abbr'\n",
    "            })\n",
    "        .select([pl.col('game_id').cast(pl.Int32),\n",
    "                 pl.col('team_id').cast(pl.Utf8),\n",
    "                 pl.col('player_id').cast(pl.Utf8),\n",
    "                 pl.col('player_name').str.to_uppercase().cast(pl.Utf8),\n",
    "                 pl.col('team_abbr').cast(pl.Utf8),\n",
    "                 pl.col('period').cast(pl.Int32),\n",
    "                 pl.col('period_start_seconds').cast(pl.Int64),\n",
    "                 pl.col('period_end_seconds').cast(pl.Int64),\n",
    "                 pl.col('game_start_seconds').cast(pl.Int64),\n",
    "                 pl.col('game_end_seconds').cast(pl.Int64)\n",
    "                 ]) #'shift_id', 'typeCode', 'shift_number', 'eventNumber'\n",
    "    )\n",
    "    shift_raw = (\n",
    "        # Join and Create team_type\n",
    "        shift_raw\n",
    "        .join(game_info_slim.select('game_id', 'home_id', 'away_id').unique(), on='game_id', how='left')\n",
    "        .filter((pl.col('home_id') == pl.col('team_id')) | (pl.col('away_id') == pl.col('team_id')))\n",
    "        .filter(pl.col('game_start_seconds') != pl.col('game_end_seconds') )\n",
    "        .with_columns(pl.when(pl.col('home_id') == pl.col('team_id')).then(pl.lit('home'))\n",
    "                        .when(pl.col('away_id') == pl.col('team_id')).then(pl.lit('away')).otherwise(pl.lit(None)).alias('team_type'))\n",
    "        .drop('home_id', 'away_id')\n",
    "        .unique()\n",
    "    )\n",
    "    # Combine Consecutive Shifts\n",
    "    gb_cols = [col for col in shift_raw.columns if col not in ['period_start_seconds', 'game_start_seconds']]\n",
    "    shift_raw = (\n",
    "        shift_raw\n",
    "        .with_columns([\n",
    "            pl.col('period_start_seconds').max().over(gb_cols).alias('period_start_seconds'),\n",
    "            pl.col('game_start_seconds').max().over(gb_cols).alias('game_start_seconds')#,\n",
    "            #pl.col('eventNumber').max().over(gb_cols).alias('eventNumber')\n",
    "        ])\n",
    "        .unique()\n",
    "        # Separate Goalies\n",
    "        .join(ROSTER_DF.with_columns([\n",
    "            (pl.col('player_id').cast(pl.Utf8).alias('player_id')),\n",
    "            (pl.col('pos_G').cast(pl.Int32).alias('pos_G'))\n",
    "        ])\n",
    "        .select('player_id', 'pos_G'), on='player_id', how='left')\n",
    "        .unique()\n",
    "        .sort('game_id', 'period', 'period_start_seconds', 'period_end_seconds')\n",
    "    )\n",
    "    # Concat Player IDs into lists for each group (i.e. event and seconds)\n",
    "    result_df = (\n",
    "        shift_raw\n",
    "        .groupby(['game_id', 'period', 'period_start_seconds', 'period_end_seconds', 'team_type', 'pos_G'])\n",
    "        .agg(\n",
    "            pl.concat_list('player_id').flatten().unique().alias('player_id_list'),\n",
    "            pl.concat_list('player_name').flatten().unique().alias('player_name_list')\n",
    "            )\n",
    "        .sort('game_id', 'period', 'period_start_seconds', 'period_end_seconds')\n",
    "    )\n",
    "    # Separate and Create Player On Columns\n",
    "    game_data = (\n",
    "         game_info_slim\n",
    "         .filter(pl.col('game_id') == i)\n",
    "         .sort('game_id', 'period', 'period_seconds', 'event_idx')\n",
    "    )\n",
    "    def apply_player_lists_pl(x, ty, pos, shift, output):\n",
    "        return get_player_lists_pl((x['game_id'], x['period'], x['period_seconds'], ty, pos, shift, output))\n",
    "    def get_player_lists_pl(x):\n",
    "        # Outline Variables\n",
    "        g_id, per, p_secs, ty, pos, shift, output = x\n",
    "        # Adjust conditions as needed\n",
    "        conditions = (\n",
    "            (result_df['game_id'] == g_id) &\n",
    "            (result_df['period'] == per) &\n",
    "            (result_df['team_type'] == ty) &\n",
    "            (result_df['pos_G'] == pos)\n",
    "        )\n",
    "        if shift == 'current':\n",
    "            conditions &= (\n",
    "                (result_df['period_start_seconds'] < p_secs) &\n",
    "                (result_df['period_end_seconds'] > p_secs)\n",
    "            )\n",
    "        elif shift == 'on':\n",
    "            conditions &= (result_df['period_start_seconds'] == p_secs)\n",
    "        elif shift == 'off':\n",
    "            conditions &= (result_df['period_end_seconds'] == p_secs)\n",
    "        filtered_rows = result_df.filter(conditions)\n",
    "\n",
    "        if output == 'id':\n",
    "            result_list = set(filtered_rows['player_id_list'].explode().to_list())\n",
    "        elif output == 'name':\n",
    "            result_list = set(filtered_rows['player_name_list'].explode().to_list())\n",
    "        \n",
    "        return ','.join(str(item) for item in result_list)\n",
    "    \n",
    "    # List of columns to generate\n",
    "    columns_to_generate = [\n",
    "        ('home', 0, 'current', 'id'),\n",
    "        ('home', 0, 'current', 'name'),\n",
    "        ('home', 0, 'on', 'id'),\n",
    "        ('home', 0, 'on', 'name'),\n",
    "        ('home', 0, 'off', 'id'),\n",
    "        ('home', 0, 'off', 'name'),\n",
    "        ('away', 0, 'current', 'id'),\n",
    "        ('away', 0, 'current', 'name'),\n",
    "        ('away', 0, 'on', 'id'),\n",
    "        ('away', 0, 'on', 'name'),\n",
    "        ('away', 0, 'off', 'id'),\n",
    "        ('away', 0, 'off', 'name'),\n",
    "        ('home', 1, 'current', 'id'),\n",
    "        ('home', 1, 'current', 'name'),\n",
    "        ('home', 1, 'on', 'id'),\n",
    "        ('home', 1, 'on', 'name'),\n",
    "        ('home', 1, 'off', 'id'),\n",
    "        ('home', 1, 'off', 'name'),\n",
    "        ('away', 1, 'current', 'id'),\n",
    "        ('away', 1, 'current', 'name'),\n",
    "        ('away', 1, 'on', 'id'),\n",
    "        ('away', 1, 'on', 'name'),\n",
    "        ('away', 1, 'off', 'id'),\n",
    "        ('away', 1, 'off', 'name')\n",
    "    ]\n",
    "\n",
    "    # Generate columns dynamically\n",
    "    for prefix, pos, shift, output in columns_to_generate:\n",
    "        if pos == 1:\n",
    "            pos_lab = 'goalie'\n",
    "        elif pos == 0:\n",
    "            pos_lab = 'skater'\n",
    "        col_name = f\"{prefix}_{pos_lab}_{shift}_{output}\"\n",
    "        game_data = game_data.with_columns([\n",
    "            pl.struct([\"game_id\", \"period\", \"period_seconds\"]).apply(lambda x: apply_player_lists_pl(x, prefix, pos, shift, output)).alias(col_name)\n",
    "        ])\n",
    "    game_start_end = ['GAME_START', 'PERIOD_START', 'GAME_END', 'PERIOD_END']\n",
    "    game_data =(\n",
    "         game_data\n",
    "         .sort('game_id', 'period', 'period_seconds', 'event_idx')\n",
    "         .filter(~pl.col('event_type').is_in(game_start_end))\n",
    "        .with_columns([\n",
    "            pl.col('event_idx').max().over(['game_id', 'period', 'period_seconds']).alias('max_event_idx')\n",
    "        ])\n",
    "        .with_columns([\n",
    "            (pl.col('game_id').cast(pl.Utf8) + '-' + pl.col('period').cast(pl.Utf8) + '-' + pl.col('period_seconds').cast(pl.Utf8)).alias('event_seconds_id'),\n",
    "            pl.when(pl.col('event_idx') == pl.col('max_event_idx')).then(pl.col('event_type')).otherwise(pl.lit(None)).alias('max_event_type')\n",
    "        ])\n",
    "        .with_columns([\n",
    "            pl.col('event_seconds_id').count().over(['game_id', 'period', 'period_seconds']).alias('count_event_seconds_id')\n",
    "        ])\n",
    "    )\n",
    "\n",
    "    teams = ['home', 'away']\n",
    "    positions = ['skater', 'goalie']\n",
    "    outputvals = ['id', 'name']\n",
    "    for team in teams:\n",
    "        for position in positions:\n",
    "            for outputval in outputvals:\n",
    "                cur_cols = f\"{team}_{position}_current_{outputval}\"\n",
    "                off_cols = f\"{team}_{position}_off_{outputval}\"\n",
    "                on_cols = f\"{team}_{position}_on_{outputval}\"\n",
    "                label1 = f\"{team}_{position}_on_{outputval}\"\n",
    "                if position == 'goalie':\n",
    "                    label2 = f\"_goalie_{outputval}\"\n",
    "                else:\n",
    "                    label2 = f\"on_{outputval}\"\n",
    "                game_data = (\n",
    "                    game_data\n",
    "                    .with_columns([\n",
    "                        pl.when((pl.col(cur_cols) != \"\") & (pl.col(on_cols)== \"\") & (pl.col(off_cols) == \"\")).then(pl.col(cur_cols))\n",
    "                          .when((pl.col(cur_cols) == \"\") & (pl.col(on_cols)!= \"\") & (pl.col(off_cols) == \"\")).then(pl.col(on_cols))\n",
    "                          .when((pl.col(cur_cols) == \"\") & (pl.col(on_cols)== \"\") & (pl.col(off_cols) != \"\")).then(pl.col(off_cols))\n",
    "                          .when((pl.col(cur_cols) == \"\") & (pl.col(on_cols)!= \"\") & (pl.col(off_cols) != \"\") & (pl.col('event_idx') == pl.col('max_event_idx'))).then(pl.col(on_cols))\n",
    "                          .when((pl.col(cur_cols) == \"\") & (pl.col(on_cols)!= \"\") & (pl.col(off_cols) != \"\") & (pl.col('event_idx') != pl.col('max_event_idx'))).then(pl.col(off_cols))\n",
    "                          .when((pl.col(cur_cols) != \"\") & (pl.col(on_cols)!= \"\") & (pl.col('event_idx') == pl.col('max_event_idx'))).then(pl.concat_str([pl.col(cur_cols),pl.lit(\",\"),pl.col(on_cols)]))\n",
    "                          .when((pl.col(cur_cols) != \"\") & (pl.col(off_cols)!= \"\") & (pl.col('event_idx') != pl.col('max_event_idx'))).then(pl.concat_str([pl.col(cur_cols),pl.lit(\",\"),pl.col(off_cols)]))\n",
    "                          .when((pl.col(cur_cols) != \"\") & (pl.col(off_cols) != \"\") & (pl.col('event_idx') == pl.col('max_event_idx'))).then(pl.col(cur_cols))\n",
    "                          .otherwise(pl.lit(None))\n",
    "                          .alias(label1)\n",
    "                    ])\n",
    "                    .with_columns([pl.col(label1).str.split_exact(',', 7)])\n",
    "                    .unnest(label1)\n",
    "                    .rename({\n",
    "                        \"field_0\" : f\"{team}_1_{label2}\",\n",
    "                        \"field_1\" : f\"{team}_2_{label2}\",\n",
    "                        \"field_2\" : f\"{team}_3_{label2}\",\n",
    "                        \"field_3\" : f\"{team}_4_{label2}\",\n",
    "                        \"field_4\" : f\"{team}_5_{label2}\",\n",
    "                        \"field_5\" : f\"{team}_6_{label2}\",\n",
    "                        \"field_6\" : f\"{team}_7_{label2}\",\n",
    "                        \"field_7\" : f\"{team}_8_{label2}\"\n",
    "                    })\n",
    "                )\n",
    "    keep_cols = ['game_id', 'period', 'game_seconds', 'period_seconds', 'event_idx',\n",
    "                 'home_1__goalie_id', 'home_1__goalie_name',\n",
    "                 'home_1_on_id', 'home_2_on_id', 'home_3_on_id', 'home_4_on_id', 'home_5_on_id', 'home_6_on_id',\n",
    "                 'home_1_on_name', 'home_2_on_name', 'home_3_on_name', 'home_4_on_name', 'home_5_on_name', 'home_6_on_name',\n",
    "                 'away_1_on_id', 'away_2_on_id', 'away_3_on_id', 'away_4_on_id', 'away_5_on_id', 'away_6_on_id',\n",
    "                 'away_1_on_name', 'away_2_on_name', 'away_3_on_name', 'away_4_on_name', 'away_5_on_name', 'away_6_on_name',\n",
    "                 'away_1__goalie_id', 'away_1__goalie_name']\n",
    "    game_data = (\n",
    "        game_data\n",
    "        .select(keep_cols)\n",
    "        .sort('game_id', 'period', 'period_seconds', 'event_idx')\n",
    "        .rename({\n",
    "            'away_1__goalie_id': 'away_goalie',\n",
    "            'away_1__goalie_name': 'away_goalie_name',\n",
    "            'home_1__goalie_id': 'home_goalie',\n",
    "            'home_1__goalie_name': 'home_goalie_name'\n",
    "        })\n",
    "    )\n",
    "\n",
    "    # Combine DataFrames\n",
    "    result_df = data.join(game_data, on = ['game_id', 'period', 'game_seconds', 'period_seconds', 'event_idx'], how = \"left\")\n",
    "\n",
    "    return result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "def load_games(load_path = 'Data/PBP/API_RAW_PBP_Data.parquet', season_start = 2012 , existing=False):\n",
    "    \"\"\"This function will load all game play by play data using the functions above to clean the raw API Data from the NHL.\n",
    "    \n",
    "    If Existing is True, the function will only load games that are not in the most current PBP_RAW Parquet File\"\"\"\n",
    "    # Get Dates\n",
    "    max_date_file = open('last_load_date.json', 'r+')\n",
    "    max_date= json.load(max_date_file)['max_date']\n",
    "    yday = datetime.today() - timedelta(days=1)\n",
    "    end_date = yday.strftime('%Y%m%d')\n",
    "    last_load = datetime.strptime(max_date, \"%Y-%m-%d\").strftime('%Y%m%d')\n",
    "\n",
    "\n",
    "    if (existing==True):\n",
    "        # Print Information\n",
    "        print(\"Now Loading Most Recent Play By Play Data From Existing File Path\", load_path)\n",
    "        start_time = time.time()\n",
    "\n",
    "        # Get Dates For Load\n",
    "        load_dates = pd.date_range(start=last_load, end=end_date, freq='D')\n",
    "\n",
    "        f_g_id = []\n",
    "        for i in load_dates:\n",
    "            i_str = i.strftime('%Y-%m-%d')\n",
    "            sched_link = \"https://api-web.nhle.com/v1/schedule/\"+i_str\n",
    "            response = requests.get(sched_link)\n",
    "\n",
    "            # Parse the JSON content of the response\n",
    "            raw_data = pd.json_normalize(response.json())\n",
    "            sched_data = pd.json_normalize(raw_data['gameWeek'][0])\n",
    "            sched_data = pd.json_normalize(sched_data['games'][0])\n",
    "\n",
    "            if len(sched_data) == 0:\n",
    "                pass\n",
    "            else:\n",
    "                sched_data = sched_data[sched_data['gameType'].isin([2,3])]\n",
    "                f_g_id.append(sched_data['id'].tolist())\n",
    "\n",
    "        # Create Lists (Game ID and Dates Loaded):\n",
    "        f_g_id = list(chain(*f_g_id))\n",
    "\n",
    "        # Load Current PBP\n",
    "        data = pl.read_parquet(load_path).sort('season', 'game_id', 'sort_order')\n",
    "        n_games = len(f_g_id)\n",
    "        start_date = min(load_dates)\n",
    "        end_date = max(load_dates)\n",
    "\n",
    "        # Initialize Data Frame List To Store Loaded Data Frames\n",
    "        df_list = []\n",
    "        \n",
    "        for i in f_g_id:\n",
    "            pbp_link = 'https://api-web.nhle.com/v1/gamecenter/'+str(i)+'/play-by-play'\n",
    "\n",
    "            pbp_response = requests.get(pbp_link)\n",
    "            pbp_data = pd.json_normalize(pbp_response.json())\n",
    "\n",
    "            ## GAME DATA\n",
    "            game_data = pbp_data[['id', 'season', 'gameDate', 'gameType', 'awayTeam.id', 'awayTeam.abbrev', 'homeTeam.id', 'homeTeam.abbrev']]\n",
    "\n",
    "            # PLAYS DATA\n",
    "            if len(pbp_data['plays']) > 0:\n",
    "                normalized_plays = pd.concat([pd.json_normalize(item) for sublist in pbp_data['plays'] for item in sublist], ignore_index=True)\n",
    "\n",
    "                result_df = pd.merge(game_data.assign(key=1), normalized_plays.assign(key=1), on='key').drop('key', axis=1)\n",
    "                result_df = pl.DataFrame(result_df)\n",
    "\n",
    "                # SLIM DF\n",
    "                result_df = align_and_cast_columns(data = result_df, sch = raw_schema)\n",
    "\n",
    "                # CLEAN FOR USE\n",
    "                result_df = reconcile_api_data(result_df)\n",
    "\n",
    "                # APPEND TO DF LIST FOR UNION\n",
    "                df_list.append(result_df)\n",
    "            else:\n",
    "                pass\n",
    "        \n",
    "        for df in df_list:\n",
    "            data.extend(df)\n",
    "            \n",
    "        data = data.sort('season', 'game_id', 'sort_order')\n",
    "\n",
    "        g_ids = data['game_id'].unique().to_list()\n",
    "        max_date_new = data['game_date'].max()\n",
    "\n",
    "        # Print Eval Statements\n",
    "        end_time = time.time()\n",
    "        elap_time = round(((end_time - start_time)/60),2)\n",
    "        rows_loaded = data.filter(pl.col('game_id').is_in(f_g_id)).height\n",
    "        print(\"Successfully Loaded\",str(rows_loaded),\"Rows from\", str(n_games), \"played between\", str(start_date), \"to\", str(end_date), \"in\", str(elap_time), \"Minutes\")\n",
    "\n",
    "        # Save\n",
    "        with open('game_ids.pkl', 'wb') as file:\n",
    "            pickle.dump(g_ids, file)\n",
    "        \n",
    "        json.dump({\"max_date\": max_date_new}, open('last_load_date.json', 'w+'))\n",
    "\n",
    "        return data\n",
    "    \n",
    "    elif(existing==False):\n",
    "        # Get Game IDs If List of Games Do Not Exist\n",
    "        g_id_file_name  = 'game_ids.pkl'\n",
    "\n",
    "        if os.path.exists(g_id_file_name):\n",
    "            with open(g_id_file_name, \"rb\") as file:\n",
    "                game_ids = pickle.load(file)\n",
    "        else:\n",
    "            print(\"Collecting and Aggregating All Game ID's\")\n",
    "            id_start = time.time()\n",
    "            st_date = str(season_start)+'1001'\n",
    "            game_ids = []\n",
    "            for i in pd.date_range(start=st_date, end=end_date, freq='D'):\n",
    "                i_str = i.strftime('%Y-%m-%d')\n",
    "                sched_link = \"https://api-web.nhle.com/v1/schedule/\"+i_str\n",
    "                response = requests.get(sched_link)\n",
    "\n",
    "                # Parse the JSON content of the response\n",
    "                raw_data = pd.json_normalize(response.json())\n",
    "                sched_data = pd.json_normalize(raw_data['gameWeek'][0])\n",
    "                sched_data = pd.json_normalize(sched_data['games'][0])\n",
    "\n",
    "                if len(sched_data) == 0:\n",
    "                    pass\n",
    "                else:\n",
    "                    sched_data = sched_data[sched_data['gameType'].isin([2,3])]\n",
    "                    game_ids.append(sched_data['id'].tolist())\n",
    "\n",
    "            # Create Lists (Game ID and Dates Loaded):\n",
    "            game_ids = list(chain(*game_ids))\n",
    "\n",
    "            # Save\n",
    "            with open('game_ids.pkl', 'wb') as file:\n",
    "                pickle.dump(game_ids, file)\n",
    "\n",
    "            id_end = time.time()\n",
    "            id_elap = round((id_end - id_start)/60, 2)\n",
    "\n",
    "            print(\"Successfully Loaded\", str(len(game_ids)), \"Game ID's From NHL Schedule in\", str(id_elap), 'minutes')\n",
    "\n",
    "        print(\"Now Loading ALL Play By Play Data From NHL API (2012-2024 Seasons)\", str(len(game_ids)), \"Games\")\n",
    "\n",
    "        start_time = time.time()\n",
    "        n_games = len(game_ids)\n",
    "\n",
    "        prev_season = int(str(season_start)+str(season_start+1))\n",
    "        prev_season_time = start_time\n",
    "\n",
    "        # Initialize Data Frame List To Store Loaded Data Frames\n",
    "        df_list = []\n",
    "        bad_ids = []\n",
    "        \n",
    "        for i in game_ids:\n",
    "            pbp_link = 'https://api-web.nhle.com/v1/gamecenter/'+str(i)+'/play-by-play'\n",
    "            # Create Try For Bad Links\n",
    "            try:\n",
    "                pbp_response = requests.get(pbp_link)\n",
    "                pbp_data = pd.json_normalize(pbp_response.json())\n",
    "                # If DF loads but no data, pass\n",
    "                if (~pbp_data['plays'].empty) | (len(pbp_data['plays']) < 0):\n",
    "                    game_data = pbp_data[['id', 'season', 'gameDate', 'gameType', 'awayTeam.id', 'awayTeam.abbrev', 'homeTeam.id', 'homeTeam.abbrev']]\n",
    "\n",
    "                    # Check if the current season is different from the previous one\n",
    "                    if (game_data['season'][0] != prev_season):\n",
    "                        season_lab = str(int(str(i)[:4])-1) +\"-\"+str(int(str(i)[:4]))\n",
    "                        season_end_time = time.time()\n",
    "                        season_elapsed_time = round((season_end_time - prev_season_time)/60,2)\n",
    "                        games_loaded = sum(1 for x in game_ids if str(x).startswith(str(int(str(i)[:4])-1))) - sum(1 for x in bad_ids if str(x).startswith(str(int(str(i)[:4])-1)))\n",
    "                        all_games_loaded = len(df_list)\n",
    "                        games_remaining = len(game_ids) - all_games_loaded\n",
    "                        gpm = ((all_games_loaded)/(season_end_time - start_time)*60)\n",
    "                        szn_gpm = ((games_loaded)/(season_end_time - prev_season_time)*60)\n",
    "                        est_time_remaining = games_remaining / gpm\n",
    "                        print(f\"Successfully Loaded {games_loaded} Games From {season_lab} Season in {season_elapsed_time} Minutes ({round(szn_gpm, 2)} GPM) | {games_remaining} Games To Load -- Est. Load Time: {round(est_time_remaining,2)} Minutes ({round(gpm, 2)} GPM) | Completed at {season_end_time}\")\n",
    "                        prev_season = game_data['season'][0]\n",
    "                        prev_season_time = season_end_time\n",
    "                    elif (i == game_ids[-1]):\n",
    "                        season_lab = str(int(str(i)[:4])) +\"-\"+str(int(str(i)[:4])+1)\n",
    "                        season_end_time = time.time()\n",
    "                        season_elapsed_time = round((season_end_time - prev_season_time)/60,2)\n",
    "                        games_loaded = sum(1 for x in game_ids if str(x).startswith(str(int(str(i)[:4])))) - sum(1 for x in bad_ids if str(x).startswith(str(int(str(i)[:4]))))\n",
    "                        all_games_loaded = len(df_list) + 1\n",
    "                        gpm = ((all_games_loaded)/(season_end_time - start_time)*60)\n",
    "                        szn_gpm = ((games_loaded)/(season_end_time - prev_season_time)*60)\n",
    "                        print(f\"Successfully Loaded {games_loaded} Games From {season_lab} Season in {season_elapsed_time} Minutes ({round(szn_gpm, 2)} GPM) | Completed at {season_end_time}\")\n",
    "\n",
    "                    # Build 'Plays' Data Frame and Combine With Game Data\n",
    "                    normalized_plays = pd.concat([pd.json_normalize(item) for sublist in pbp_data['plays'] for item in sublist], ignore_index=True)\n",
    "                    result_df = pd.merge(game_data.assign(key=1), normalized_plays.assign(key=1), on='key').drop('key', axis=1)\n",
    "                    result_df = pl.DataFrame(result_df)\n",
    "\n",
    "                    # Slim Game DataFrame\n",
    "                    result_df = align_and_cast_columns(data = result_df, sch = raw_schema)\n",
    "\n",
    "                    # Clean Game Data for Model Application\n",
    "                    result_df = reconcile_api_data(result_df)\n",
    "\n",
    "                    # Append Shift Data To Clean PBP\n",
    "                    result_df = append_shift_data(result_df)\n",
    "\n",
    "                    # Append Single Game Data To List For Union\n",
    "                    df_list.append(result_df)\n",
    "\n",
    "                else:\n",
    "                    pass\n",
    "            except ValueError as e:\n",
    "                print(f\"Bad Link for GameID {i} | Error: {e}\")\n",
    "                bad_ids.append(i)\n",
    "                continue\n",
    "\n",
    "        print(\"Begin Union of Final DataFrame\")\n",
    "            \n",
    "        \n",
    "        data = df_list[0]\n",
    "        for df in df_list[1:]:\n",
    "            data.extend(df)\n",
    "        data = data.sort('season', 'game_id', 'sort_order')\n",
    "\n",
    "        # Print Eval Statements\n",
    "        max_date_new = data['game_date'].max()\n",
    "        min_date = data['game_date'].min()\n",
    "        rows_loaded = data.height\n",
    "\n",
    "        end_time = time.time()\n",
    "        elap_time = round(((end_time - start_time)/3600),2)\n",
    "\n",
    "        print(\"Successfully Loaded\",str(rows_loaded),\"Rows from\", str(n_games), \"played between\", str(min_date), \"to\", str(max_date_new), \"in\", str(elap_time), \"Hours\")\n",
    "        print(\"Rows By Season:\")\n",
    "        print(data['season'].value_counts().sort('season', descending=True))\n",
    "        print(len(list(chain(*bad_ids))), \"Bad IDs - Failed To Load - No Data\")\n",
    "\n",
    "\n",
    "        # Save\n",
    "        json.dump({\"max_date\": max_date_new}, open('last_load_date.json', 'w+'))\n",
    "\n",
    "        with open('bad_ids.pkl', 'wb') as file:\n",
    "            pickle.dump(list(chain(*bad_ids)), file)\n",
    "\n",
    "        return data\n",
    "    else:\n",
    "        print(\"Wrong Inputs - Please Try Again\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now Loading ALL Play By Play Data From NHL API (2012-2024 Seasons) 14168 Games\n"
     ]
    }
   ],
   "source": [
    "PBP_RAW = load_games(load_path='Data/PBP/API_RAW_PBP_Data.parquet', existing=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PBP_Path = \"Data/PBP/API_RAW_PBP_Data.parquet\"\n",
    "PBP_RAW.write_parquet(\n",
    "    PBP_Path,\n",
    "    use_pyarrow=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PBP_RAW.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Roster File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path\n",
    "roster_file = 'Data/NHL_Rosters_2014_2024.csv'\n",
    "\n",
    "# All Players - Connect To event_player_1_id, event_player_2_id, event_player_3_id, event_player_4_id, event_goalie_id, home_goalie, away_goalie\n",
    "ROSTER_DF_RAW = pl.read_csv(roster_file)\n",
    "\n",
    "ROSTER_DF = (\n",
    "    ROSTER_DF_RAW\n",
    "    .with_columns([\n",
    "        pl.col(\"player_id\").cast(pl.Int32),\n",
    "        (pl.col(\"first_name\").str.to_uppercase() + '.' + pl.col(\"last_name\").str.to_uppercase()).alias('player_name'),\n",
    "        pl.when((pl.col('pos_G') == 1) & (pl.col('hand_R') == 1)).then(pl.lit(1)).otherwise(pl.lit(0)).alias('G_hand_R'),\n",
    "        pl.when((pl.col('pos_G') == 1) & (pl.col('hand_L') == 1)).then(pl.lit(1)).otherwise(pl.lit(0)).alias('G_hand_L')\n",
    "        ])\n",
    "    .select(['player_id', 'player_name', 'hand_R', 'hand_L', 'pos_F', 'pos_D', 'pos_G', 'G_hand_R', 'G_hand_L'])\n",
    "    .unique()\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PBP_RAW.filter(pl.col('event_type')=='GOAL')['strength_state'].value_counts().sort(\"counts\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sdv_cols = ['event_type', 'event', 'description', 'period', 'period_seconds', 'period_seconds_remaining', 'game_seconds', 'game_seconds_remaining', 'home_score', 'away_score', 'strength_state', 'event_idx', 'extra_attacker', 'home_skaters', 'away_skaters', 'game_id', 'period_type', 'ordinal_num', 'period_time', 'period_time_remaining', 'date_time', 'home_final', 'away_final', 'season', 'season_type', 'game_date', 'game_start', 'game_end', 'game_length', 'game_state', 'detailed_state', 'venue_name', 'venue_link', 'home_name', 'home_abbreviation', 'home_division_name', 'home_conference_name', 'home_id', 'away_name', 'away_abbreviation', 'away_division_name', 'away_conference_name', 'away_id', 'event_id', 'event_team', 'event_team_type', 'num_on', 'players_on', 'players_off', 'away_on_1', 'away_on_2', 'away_on_3', 'away_on_4', 'away_on_5', 'away_goalie', 'ids_on', 'ids_off', 'secondary_type', 'home_on_1', 'home_on_2', 'home_on_3', 'home_on_4', 'home_on_5', 'home_goalie', 'event_player_1_name', 'event_player_1_type', 'event_player_2_name', 'event_player_2_type', 'strength_code', 'strength', 'x', 'y', 'x_fixed', 'y_fixed', 'event_player_1_id', 'event_player_1_link', 'event_player_2_id', 'event_player_2_link', 'event_team_id', 'event_team_link', 'event_team_abbr', 'num_off', 'penalty_severity', 'penalty_minutes', 'away_on_6', 'shot_distance', 'shot_angle', 'event_goalie_name', 'event_goalie_id', 'event_goalie_link', 'event_goalie_type', 'event_player_3_name', 'event_player_3_type', 'game_winning_goal', 'empty_net', 'event_player_3_id', 'event_player_3_link', 'event_player_4_type', 'event_player_4_id', 'event_player_4_name', 'event_player_4_link', 'home_on_6', 'venue_id']\n",
    "\n",
    "# Check Similar Columns:\n",
    "sim_cols = [l for l in sdv_cols if l in PBP_RAW.columns]\n",
    "\n",
    "# Check SDV Not In API Cols\n",
    "ignore_cols = ['event', 'description', 'extra_attacker', 'ordinal_num', 'period_time', 'period_time_remaining', 'home_final', 'away_final', 'game_start', 'game_end', 'game_length', 'game_state', 'detailed_state']\n",
    "sdv_not_api = [l for l in sdv_cols if (l not in PBP_RAW.columns) & (~l.endswith('_link'))]\n",
    "\n",
    "# Check API Not In SDV Cols\n",
    "api_not_sdv = [l for l in PBP_RAW.columns if l not in sdv_cols]\n",
    "\n",
    "print(sim_cols)\n",
    "print(len(sim_cols))\n",
    "\n",
    "print(sdv_not_api)\n",
    "print(len(sdv_not_api))\n",
    "\n",
    "print(api_not_sdv)\n",
    "print(len(api_not_sdv))\n",
    "\n",
    "## Columns To Create:\n",
    "\n",
    "# Shift Related\n",
    "    # away_goalie / home_goalie\n",
    "    # event_player_1_name, event_player_2_name, event_player_3_name, event_player_4_name, event_goalie_name\n",
    "    # home_on_1, home_on_2, home_on_3, home_on_5, home_on_6\n",
    "    # away_on_1, away_on_2, away_on_3, away_on_5, away_on_6\n",
    "\n",
    "    # *num_on\n",
    "    # *players_on/players_off\n",
    "    # *ids_on/ids_off\n",
    "\n",
    "   \n",
    "\n",
    "# Ignore\n",
    "\n",
    "    # event\n",
    "    # description\n",
    "    # ordinal_num\n",
    "    # home_final\n",
    "    # away_final\n",
    "    # num_off\n",
    "    # penalty_severity\n",
    "    # Extra Attacker\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Shift Data\n",
    "\n",
    "- This will be joined to the PBP_RAW Table and create columns for which players were on the ice at a given event.\n",
    "- In this cell block, we will create the shift columns needed:\n",
    "    - *home_on_1, home_on_2, home_on_3, home_on_5, home_on_6, home_goalie*\n",
    "    - *away_on_1, away_on_2, away_on_3, away_on_5, away_on_6, away_goalie*\n",
    "- I believe I have two options on the join:\n",
    "    - 1) Create a table with every seconds from the game and inner join home/away players\n",
    "        - May create too large of a table for each join (max height = 9600 rows | normal height = 3600 rows)\n",
    "    - 2) Diagonally Union the table\n",
    "        - Need to figure out which columns from PBP_RAW will be null (possibly fill_na(method = 'forward')? )\n",
    "        - Need to figure out join key and create \"CHANGE\" event_type as well as other types associated (on the fly vs stoppage?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path\n",
    "roster_file = 'NHL_Rosters_2014_2024.csv'\n",
    "\n",
    "# All Players - Connect To event_player_1_id, event_player_2_id, event_player_3_id, event_player_4_id, event_goalie_id, home_goalie, away_goalie\n",
    "ROSTER_DF_RAW = pl.read_csv(roster_file)\n",
    "\n",
    "ROSTER_DF = (\n",
    "    ROSTER_DF_RAW\n",
    "    .with_columns([\n",
    "        pl.col(\"player_id\").cast(pl.Int32),\n",
    "        (pl.col(\"first_name\").str.to_uppercase() + '.' + pl.col(\"last_name\").str.to_uppercase()).alias('player_name'),\n",
    "        pl.when((pl.col('pos_G') == 1) & (pl.col('hand_R') == 1)).then(pl.lit(1)).otherwise(pl.lit(0)).alias('G_hand_R'),\n",
    "        pl.when((pl.col('pos_G') == 1) & (pl.col('hand_L') == 1)).then(pl.lit(1)).otherwise(pl.lit(0)).alias('G_hand_L')\n",
    "        ])\n",
    "    .select(['player_id', 'player_name', 'hand_R', 'hand_L', 'pos_F', 'pos_D', 'pos_G', 'G_hand_R', 'G_hand_L'])\n",
    "    .unique()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shift Data\n",
    "# Load Game ID and Home/Away Ids\n",
    "def append_shift_data(data):\n",
    "    \"\"\"This function will take the game ID from the api load and create columns for players on ice during given events.\"\"\"\n",
    "\n",
    "    for i in PBP_RAW['game_id'].unique():\n",
    "        shift_link = \"https://api.nhle.com/stats/rest/en/shiftcharts?cayenneExp=gameId=\"+str(i)\n",
    "        shift_response = requests.get(shift_link)\n",
    "        shift_raw = pd.json_normalize(shift_response.json())\n",
    "        shift_raw = pd.json_normalize(shift_raw['data'])\n",
    "\n",
    "\n",
    "        # Create an empty DataFrame to store the normalized plays\n",
    "        normalized_shift = pd.DataFrame()\n",
    "\n",
    "        # Iterate over each row in plays_1 and normalize the JSON data\n",
    "        for _, row in shift_raw.iterrows():\n",
    "            # Normalize the JSON data in the current row\n",
    "            normalized_row_g = pd.json_normalize(row)\n",
    "\n",
    "            # Concatenate the normalized row to the result DataFrame\n",
    "            normalized_shift = pd.concat([normalized_shift, normalized_row_g], ignore_index=True)\n",
    "\n",
    "        # Create Columns From Data (Names and Shift Starts)\n",
    "        normalized_shift['player_name'] = normalized_shift['firstName'] + ' ' + normalized_shift['lastName']\n",
    "        # Period Time\n",
    "        normalized_shift['period_start_seconds'] = pd.to_datetime(normalized_shift['startTime'], format='%M:%S').dt.minute * 60 + pd.to_datetime(normalized_shift['startTime'], format='%M:%S').dt.second\n",
    "        normalized_shift['period_end_seconds'] = pd.to_datetime(normalized_shift['endTime'], format='%M:%S').dt.minute * 60 + pd.to_datetime(normalized_shift['endTime'], format='%M:%S').dt.second\n",
    "        # Game Time\n",
    "        normalized_shift['game_start_seconds'] = ( pd.to_datetime(normalized_shift['startTime'], format='%M:%S').dt.minute * 60 + pd.to_datetime(normalized_shift['startTime'], format='%M:%S').dt.second) + ((normalized_shift['period'] - 1) * 1200)\n",
    "        normalized_shift['game_end_seconds'] = ( pd.to_datetime(normalized_shift['endTime'], format='%M:%S').dt.minute * 60 + pd.to_datetime(normalized_shift['endTime'], format='%M:%S').dt.second) + ((normalized_shift['period'] - 1) * 1200)\n",
    "\n",
    "        # Rename\n",
    "        normalized_shift = normalized_shift.rename(columns = {\n",
    "            'gameId': 'game_id',\n",
    "            'id': 'shift_id',\n",
    "            'playerId': 'player_id',\n",
    "            'teamId': 'team_id',\n",
    "            'shiftNumber': 'shift_number',\n",
    "            'teamAbbrev': 'team_abbr'\n",
    "        })\n",
    "\n",
    "        # Keep\n",
    "        shift_keep_cols = ['game_id', 'shift_id', 'team_id', 'player_id', 'player_name', 'period',\n",
    "                           'period_start_seconds', 'period_end_seconds', 'game_start_seconds', 'game_end_seconds',\n",
    "                           'eventNumber', 'team_abbr', 'shift_number', 'typeCode']\n",
    "        normalized_shift = normalized_shift[shift_keep_cols]\n",
    "        normalized_shift = pl.DataFrame(normalized_shift)\n",
    "\n",
    "        # Join To Get Home Team\n",
    "        normalized_shift = (\n",
    "            normalized_shift\n",
    "            .join(data.drop('game_seconds', 'period_seconds', 'event_id', 'event_idx', 'event_type').unique(), on='game_id', how='left')\n",
    "            .with_columns(pl.when(pl.col('home_id') == pl.col('team_id')).then(pl.lit('home')).otherwise(pl.lit('away')).alias('team_type'))\n",
    "            .drop('home_id', 'away_id')\n",
    "            .unique()\n",
    "        )\n",
    "\n",
    "        # Join To Separate Goalies\n",
    "        normalized_shift = (\n",
    "            normalized_shift\n",
    "            .join(ROSTER_DF.with_columns([\n",
    "                (pl.col('player_id').cast(pl.Int64).alias('player_id')),\n",
    "                (pl.col('pos_G').cast(pl.Int64).alias('pos_G'))\n",
    "            ])\n",
    "            .select('player_id', 'pos_G'), on='player_id', how='left')\n",
    "            .unique()\n",
    "        )\n",
    "\n",
    "\n",
    "        # Group by 'player_id'\n",
    "        grouped_shifts = normalized_shift.select('player_id', 'game_id', 'period', 'team_type', 'pos_G', 'period_start_seconds', 'period_end_seconds').to_pandas()\n",
    "        grouped_shifts = grouped_shifts.groupby(['game_id', 'period', 'period_start_seconds', 'period_end_seconds', 'team_type', 'pos_G'])\n",
    "\n",
    "        # Aggregate using the agg method\n",
    "        result_df = grouped_shifts.agg(\n",
    "            player_id_list=('player_id', list),\n",
    "        ).reset_index()\n",
    "\n",
    "        seconds_df = PBP_RAW.select(pl.col('game_id').cast(pl.Int64),pl.col('period').cast(pl.Int64), pl.col('period_seconds').cast(pl.Int64), 'event_idx').filter(pl.col('game_id') == i).to_pandas()\n",
    "\n",
    "\n",
    "        # Function to get player lists based on conditions\n",
    "        def get_player_lists(row, type, pos):\n",
    "            p_secs = row['period_seconds']\n",
    "            per = row['period']\n",
    "\n",
    "            # Adjust conditions as needed\n",
    "            condition = (\n",
    "                (result_df['period'] == per) &\n",
    "                (result_df['period_start_seconds'] <= p_secs) &\n",
    "                (result_df['period_end_seconds'] > p_secs) &\n",
    "                (result_df['team_type'] == type) &\n",
    "                (result_df['pos_G'] == pos)\n",
    "            )\n",
    "\n",
    "            selected_rows = result_df[condition]\n",
    "\n",
    "            if not selected_rows.empty:\n",
    "                # Combine player lists\n",
    "                combined_players = [player_id for player_list in selected_rows['player_id_list'] for player_id in player_list]\n",
    "                return combined_players\n",
    "            else:\n",
    "                return []\n",
    "\n",
    "        # Apply the function to each row of seconds_df\n",
    "        seconds_df['home'] = seconds_df.apply(get_player_lists,type='home', pos=0, axis=1)\n",
    "        seconds_df['away'] = seconds_df.apply(get_player_lists,type='away', pos=0, axis=1)\n",
    "        seconds_df['home_goalie'] = seconds_df.apply(get_player_lists, type='home', pos=1, axis=1)\n",
    "        seconds_df['away_goalie'] = seconds_df.apply(get_player_lists, type='away', pos=1, axis=1)\n",
    "\n",
    "        # Columns with lists of player IDs\n",
    "        list_columns = [\"home\", \"away\", \"home_goalie\", \"away_goalie\"]\n",
    "\n",
    "        # Iterate over each list column\n",
    "        for column in list_columns:\n",
    "            # Iterate over each row\n",
    "            for index, row in seconds_df.iterrows():\n",
    "                # Extract the list of player IDs\n",
    "                player_ids = row[column]\n",
    "\n",
    "                # Iterate over the player IDs in the list\n",
    "                for i, player_id in enumerate(player_ids):\n",
    "                    # Create a new column name\n",
    "                    new_column_name = f\"{column}_{i+1}_on\"\n",
    "\n",
    "                    # Create a new column in the DataFrame\n",
    "                    seconds_df.at[index, new_column_name] = player_id\n",
    "\n",
    "        # Drop unnecessary Columns\n",
    "        seconds_df = seconds_df.drop(['home', 'away', 'home_goalie', 'away_goalie'], axis=1)\n",
    "\n",
    "# Combine DataFrames\n",
    "final_shift_df = pd.concat(shift_df_list)\n",
    "# Display the updated DataFrame\n",
    "print(final_shift_df.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Roster Data\n",
    "\n",
    "- Here I have a couple options to go about how I want to connect roster data for joins to event_player_id (and all other event_player_id columns)\n",
    "    - **Use LoadRosters.py**\n",
    "        - Pros:\n",
    "            - Already created\n",
    "            - Join structure exists\n",
    "            - Has all columns I would need\n",
    "            - Can be joined to shift data?\n",
    "        - Cons:\n",
    "            - May not have the most current players (Some mismatched joins here)\n",
    "    - **Hit Rosters from beginning of PBP API**\n",
    "        - Pros:\n",
    "            - Each game is unique and all players in game will be matched (all players from this source are in the game)\n",
    "        - Cons:\n",
    "            - Load time\n",
    "            - Build query time\n",
    "            - Still need to join rosters some "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Option 1: Load Rosters From LoadRosters.py Script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path\n",
    "roster_file = 'NHL_Rosters_2014_2024.csv'\n",
    "\n",
    "# All Players - Connect To event_player_1_id, event_player_2_id, event_player_3_id, event_player_4_id, event_goalie_id, home_goalie, away_goalie\n",
    "ROSTER_DF_RAW = pl.read_csv(roster_file)\n",
    "\n",
    "ROSTER_DF = (\n",
    "    ROSTER_DF_RAW\n",
    "    .with_columns([\n",
    "        pl.col(\"player_id\").cast(pl.Int32),\n",
    "        (pl.col(\"first_name\").str.to_uppercase() + '.' + pl.col(\"last_name\").str.to_uppercase()).alias('player_name'),\n",
    "        pl.when((pl.col('pos_G') == 1) & (pl.col('hand_R') == 1)).then(pl.lit(1)).otherwise(pl.lit(0)).alias('G_hand_R'),\n",
    "        pl.when((pl.col('pos_G') == 1) & (pl.col('hand_L') == 1)).then(pl.lit(1)).otherwise(pl.lit(0)).alias('G_hand_L')\n",
    "        ])\n",
    "    .select(['player_id', 'player_name', 'hand_R', 'hand_L', 'pos_F', 'pos_D', 'pos_G', 'G_hand_R', 'G_hand_L'])\n",
    "    .unique()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Option 2: Load Rosters From Start of Game"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_list = []\n",
    "for i in [2021020001]:\n",
    "    pbp_link = 'https://api-web.nhle.com/v1/gamecenter/'+str(i)+'/play-by-play'\n",
    "\n",
    "    pbp_response = requests.get(pbp_link)\n",
    "    pbp_data = pd.json_normalize(pbp_response.json())\n",
    "    pbp_data = pbp_data[pbp_data['gameType'] != 1]\n",
    "\n",
    "    ## GAME DATA\n",
    "    game_data = pbp_data[['id', 'season', 'gameDate', 'gameType', 'awayTeam.id', 'awayTeam.abbrev', 'homeTeam.id', 'homeTeam.abbrev']]\n",
    "\n",
    "    ## PLAYS DATA\n",
    "    roster_spots = pd.json_normalize(pbp_data['rosterSpots'])\n",
    "#\n",
    "    ## Create an empty DataFrame to store the normalized plays\n",
    "    #normalized_plays = pd.DataFrame()\n",
    "#\n",
    "    ## Iterate over each row in plays_1 and normalize the JSON data\n",
    "    #for _, row in plays_1.iterrows():\n",
    "    #    # Normalize the JSON data in the current row\n",
    "    #    normalized_row = pd.json_normalize(row)\n",
    "#\n",
    "    #    # Concatenate the normalized row to the result DataFrame\n",
    "    #    normalized_plays = pd.concat([normalized_plays, normalized_row], ignore_index=True)\n",
    "#\n",
    "    #result_df = pd.merge(game_data.assign(key=1), normalized_plays.assign(key=1), on='key').drop('key', axis=1)\n",
    "    #result_df = pl.DataFrame(result_df)\n",
    "#\n",
    "    #df_list.append(result_df)\n",
    "    \n",
    "print('Loading Complete -- Begin Diagonal Union of', len(df_list),'Games')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### *Check Options by Join Rate*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "id_check = 'event_player_1_id'\n",
    "dist_ids = pl.DataFrame({id_check: PBP_RAW.filter(~pl.col(id_check).is_null())[id_check].cast(pl.Int32).unique()})\n",
    "\n",
    "## Option 1 ##\n",
    "test_roster_join_1 = dist_ids.join(ROSTER_DF, left_on=id_check, right_on='player_id', how = 'left')\n",
    "\n",
    "print(\"inner_join\", dist_ids.join(ROSTER_DF, left_on=id_check, right_on='player_id', how = 'inner').height)\n",
    "print(\"left_join\", dist_ids.join(ROSTER_DF, left_on=id_check, right_on='player_id', how = 'left').height)\n",
    "print(\"outer_join\", dist_ids.join(ROSTER_DF, left_on=id_check, right_on='player_id', how = 'outer').height)\n",
    "\n",
    "good_ids = dist_ids.join(ROSTER_DF, left_on=id_check, right_on='player_id', how = 'inner').select(id_check).unique()\n",
    "good_ids = good_ids[id_check].to_list()\n",
    "\n",
    "null_ids_outer = dist_ids.join(ROSTER_DF, left_on=id_check, right_on='player_id', how = 'left').filter(~pl.col(id_check).is_in(good_ids))\n",
    "print(null_ids_outer.height)\n",
    "print(null_ids_outer.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PBP_RAW.filter(pl.col('event_player_1_id') == 8471279).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PBP_RAW['season_type'].value_counts().sort('counts', descending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with pl.Config(set_fmt_float=\"full\"):\n",
    "    print(PBP_RAW.filter(pl.col('season_type') == \"I\").select('game_id').unique().head())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
